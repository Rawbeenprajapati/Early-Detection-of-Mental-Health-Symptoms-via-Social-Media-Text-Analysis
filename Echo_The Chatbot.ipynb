{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d134f3-e23a-4868-88b5-d16999f60eef",
   "metadata": {},
   "source": [
    "# Echo â€“ listens and reflects feelings back, symbolizing understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446afb6c-1d53-44d6-81f6-fc28467cb3dd",
   "metadata": {},
   "source": [
    "**Chatbot Skeleton**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b30032b4-14f9-49b8-91cf-17473b0de581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import praw\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pre-processing libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "import unicodedata\n",
    "import string\n",
    "import contractions\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from translatepy import Translator\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c4414c8-a7db-4b46-9450-be37c965f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(raw_text: str) -> str:\n",
    "    EMOTION_MAP = {\n",
    "        # ðŸ˜¢ Sad / Negative / Depressed\n",
    "        \"ðŸ˜­\": \"crying\",\n",
    "        \"ðŸ’”\": \"broken_heart\",\n",
    "        \"ðŸ˜”\": \"sad\",\n",
    "        \"ðŸ˜¢\": \"tears\",\n",
    "        \"ðŸ˜ž\": \"disappointed\",\n",
    "        \"ðŸ˜“\": \"anxious\",\n",
    "        \"ðŸ˜Ÿ\": \"worried\",\n",
    "        \"ðŸ™\": \"unhappy\",\n",
    "        \"ðŸ˜©\": \"exhausted\",\n",
    "        \"ðŸ˜«\": \"tired\",\n",
    "        \"ðŸ˜–\": \"frustrated\",\n",
    "        \"ðŸ˜£\": \"distressed\",\n",
    "        \"ðŸ¥º\": \"pleading\",\n",
    "        \"ðŸ˜¿\": \"crying_cat\",\n",
    "        \"â˜¹ï¸\": \"frowning\",\n",
    "        \n",
    "        # ðŸ™‚ Neutral / Thinking\n",
    "        \"ðŸ˜\": \"neutral\",\n",
    "        \"ðŸ¤”\": \"thinking\",\n",
    "        \"ðŸ™„\": \"eye_roll\",\n",
    "        \n",
    "        # ðŸ˜€ Happy / Positive (less emphasized)\n",
    "        \"ðŸ˜‚\": \"laughing\",\n",
    "        \"ðŸ˜\": \"grinning\",\n",
    "        \"ðŸ˜Š\": \"happy\",\n",
    "        \"ðŸ˜\": \"love\",\n",
    "        \"â¤\": \"love\",\n",
    "        \"ðŸ¤—\": \"hugging\",\n",
    "        \"ðŸŽ‰\": \"celebration\"\n",
    "    }\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    translator = Translator()\n",
    "    \n",
    "    # ======================\n",
    "    # Helper Functions\n",
    "    # ======================\n",
    "    def expand_contractions(text):\n",
    "        return contractions.fix(text)\n",
    "    \n",
    "    def handle_special_characters(text):\n",
    "        text = str(text)\n",
    "        text = re.sub(r'[\\u200b-\\u200f\\u202a-\\u202e]', '', text)  # invisible chars\n",
    "        text = re.sub(r'[â¤â™¡â™¥]', 'heart', text)\n",
    "        text = re.sub(r'[â˜…â˜†âœ®âœ¯]', 'star', text)\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        return text.encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    def replace_emojis(text):\n",
    "        for emoji_char, label in EMOTION_MAP.items():\n",
    "            text = text.replace(emoji_char, f\" {label}\")\n",
    "        return text\n",
    "    \n",
    "    def translate_to_english(text):\n",
    "        try:\n",
    "            if not text.strip():\n",
    "                return text\n",
    "            result = translator.translate(text, \"English\")\n",
    "            translated_text = result.result\n",
    "            if translated_text.strip().lower() == text.strip().lower():\n",
    "                return text\n",
    "            else:\n",
    "                return translated_text\n",
    "        except Exception:\n",
    "            return text\n",
    "    text = str(raw_text).strip()\n",
    "    \n",
    "    # Replace emojis first\n",
    "    text = replace_emojis(text)\n",
    "    \n",
    "    # Translate, expand, handle special chars\n",
    "    text = text.lower()\n",
    "    text = translate_to_english(text)\n",
    "    text = expand_contractions(text)\n",
    "    text = handle_special_characters(text)\n",
    "    \n",
    "    # Remove unwanted punctuation (keep underscores)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "\n",
    "    # trimming\n",
    "    text = ' '.join(text.split()[:400])\n",
    "\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = [t for t in text.split() if t not in stop_words]\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6d98a519-5eb9-4e4f-8c68-cdd9bcdd407c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello laughing dark place last 2 years reached lowest point reflecting exactly point last 27 years life remaining potentially 40 look like quite happy person younger care world felt grounded reality enjoyed time friends family even though upbringing low socioeconomic even though raised single parent felt motivated felt great things would happen life failed high school squandered serious relationship ever wondered aimlessly 23 playing video games jobs fast forward money 5th year meant 4 year degree repeated 3rd year twice like 50k debt fail degree know man feel like even pass degree want job degree preparing know want know people normally illusion said someone 27 money barely work experience would eyebrows raising want functional human cannot find purpose cannot find anything drive reaching hopes someone maybe similar situation could would light go find purpose'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = preprocess_text(\"helloðŸ˜‚ dark place last 2 years reached lowest point reflecting exactly point last 27 years life remaining potentially 40 look like quite happy person younger care world felt grounded reality enjoyed time friends family even though upbringing low socioeconomic even though raised single parent felt motivated felt great things would happen life failed high school squandered serious relationship ever wondered aimlessly 23 playing video games jobs fast forward money 5th year meant 4 year degree repeated 3rd year twice like 50k debt fail degree know man feel like even pass degree want job degree preparing know want know people normally illusion said someone 27 money barely work experience would eyebrows raising want functional human cannot find purpose cannot find anything drive reaching hopes someone maybe similar situation could would light go find purpose\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "acd1766f-2920-4a62-87f3-e7a7fbc2b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_severity(text: str) -> float:\n",
    "    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "    import numpy as np\n",
    "\n",
    "    # Load model globally so we donâ€™t reload every call\n",
    "    model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    labels = ['Negative', 'Neutral', 'Positive']\n",
    "    \n",
    "    # Valence and arousal mapping\n",
    "    valence_map = {'Positive': 1.0, 'Neutral': 0.0, 'Negative': -1.0}\n",
    "    arousal_map = {'Positive': 0.7, 'Neutral': 0.5, 'Negative': 0.8}\n",
    "    \n",
    "    def get_sentiment(text):\n",
    "        encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "        output = model(**encoded_input)\n",
    "        scores = output.logits.detach().numpy()[0]\n",
    "        probs = np.exp(scores) / np.exp(scores).sum()\n",
    "        return dict(zip(labels, probs))\n",
    "    \n",
    "    sentiment = get_sentiment(text)\n",
    "\n",
    "    # Valence & arousal\n",
    "    valence = (\n",
    "        sentiment['Positive'] * valence_map['Positive'] +\n",
    "        sentiment['Neutral']  * valence_map['Neutral'] +\n",
    "        sentiment['Negative'] * valence_map['Negative']\n",
    "    )\n",
    "    arousal = (\n",
    "        sentiment['Positive'] * arousal_map['Positive'] +\n",
    "        sentiment['Neutral']  * arousal_map['Neutral'] +\n",
    "        sentiment['Negative'] * arousal_map['Negative']\n",
    "    )\n",
    "\n",
    "    # Raw severity\n",
    "    raw_severity = -valence * arousal\n",
    "\n",
    "    # âœ… Scale from [-1,1] â†’ [0,1]\n",
    "    severity = (raw_severity + 1) / 2\n",
    "\n",
    "    return float(severity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d9025c54-cdaa-4533-8e32-d46e3b50871d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8898738622665405"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "severity = compute_severity(\"life seriously worst like cannot say much people start judging say life like butttt seriously fucked every fucking negative trait life literally wreck trying fix years cannot energy continue everyone seems something going shit wtfwtf lowk want end icl cryingcryingbroken_heartbroken_heartbroken_heart\")\n",
    "severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ac607da3-b162-4cd2-9661-5005030f9e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! I'm here to chat with you. Type 'exit' to end.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  i am going to kill myselfðŸ˜ž\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: I'm here with you. How are you feeling right now?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Goodbye! Take care.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -----------------------------\n",
    "# Load or define severity thresholds\n",
    "# -----------------------------\n",
    "p75 = 0.86  # Moderate\n",
    "p90 = 0.94 # High\n",
    "p95 = 0.97 # Critical\n",
    "\n",
    "def assign_risk(sev):\n",
    "    if sev <= p75:\n",
    "        return \"Low\"\n",
    "    elif sev <= p90:\n",
    "        return \"Moderate\"\n",
    "    elif sev <= p95:\n",
    "        return \"High\"\n",
    "    else:\n",
    "        return \"Critical\"\n",
    "\n",
    "# -----------------------------\n",
    "# Placeholder functions\n",
    "# -----------------------------\n",
    "\n",
    "def alert_helpline(user_id, text, severity):\n",
    "    print(f\"ALERT: Critical risk detected for {user_id} | Severity: {severity:.2f}\")\n",
    "    # Here you can integrate with SMS/email/API to contact help line\n",
    "\n",
    "# -----------------------------\n",
    "# Logging function\n",
    "# -----------------------------\n",
    "def log_message(user_id, text, processed, severity, risk_level, file_path=\"output/chat_log_with_severity.csv\"):\n",
    "    df = pd.DataFrame([{\n",
    "        \"timestamp\": datetime.utcnow(),\n",
    "        \"user_id\": user_id,\n",
    "        \"text\": text,\n",
    "        \"Pre_processed_text\":processed,\n",
    "        \"severity\": severity,\n",
    "        \"risk_level\": risk_level\n",
    "    }])\n",
    "    \n",
    "    # If file exists, append without header. If not, write header.\n",
    "    if not os.path.isfile(file_path):\n",
    "        df.to_csv(file_path, mode='w', header=True, index=False)\n",
    "    else:\n",
    "        df.to_csv(file_path, mode='a', header=False, index=False)\n",
    "\n",
    "# -----------------------------\n",
    "# Background severity checker\n",
    "# -----------------------------\n",
    "def monitor_severity(user_id, text):\n",
    "    processed = preprocess_text(text)\n",
    "    severity = compute_severity(processed)\n",
    "    risk_level = assign_risk(severity)\n",
    "    \n",
    "    # Log the message\n",
    "    log_message(user_id, text, processed, severity, risk_level)\n",
    "    \n",
    "    # Trigger alert if critical\n",
    "    if risk_level == \"Critical\":\n",
    "        alert_helpline(user_id, processed, severity)\n",
    "    \n",
    "    return severity, risk_level\n",
    "\n",
    "# -----------------------------\n",
    "# Chatbot main loop (simplified)\n",
    "# -----------------------------\n",
    "def chatbot():\n",
    "    user_id = \"user123\"\n",
    "    print(\"Chatbot: Hello! I'm here to chat with you. Type 'exit' to end.\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Chatbot: Goodbye! Take care.\")\n",
    "            break\n",
    "        \n",
    "        # Run severity monitoring in a separate thread so chatbot remains responsive\n",
    "        severity_thread = threading.Thread(target=monitor_severity, args=(user_id, user_input))\n",
    "        severity_thread.start()\n",
    "        \n",
    "        # Respond to user (simple placeholder responses)\n",
    "        if np.random.rand() > 0.5:\n",
    "            response = \"I'm here with you. How are you feeling right now?\"\n",
    "        else:\n",
    "            response = \"Thank you for sharing. Tell me more about that.\"\n",
    "        print(f\"Chatbot: {response}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Start chatbot\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e108d4-c080-4395-8dab-7f050b74eba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
